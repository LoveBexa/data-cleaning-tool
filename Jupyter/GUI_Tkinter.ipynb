{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-learning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...10% Dropping empty cells\n",
      "...30% Stripping spaces\n",
      "...40% Converting all to uppercase\n",
      "...60% Slicing out & cleaning seating column\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-af56d26ca6ff>:284: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['PE DESCRIPTION'] = df['PE DESCRIPTION'].str.replace(r\" \\(.*\\)\",\"\") # print(pe_list)\n",
      "<ipython-input-3-af56d26ca6ff>:291: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['SEATING'] = df['SEATING'].str.replace('[a-zA-Z,. ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...80% Cleaning last bits\n",
      "...100%\n",
      "  FACILITY ID    FACILITY NAME  RECORD ID     PROGRAM NAME  \\\n",
      "0   FA0019645    DREAM DINNERS  PR0045642    DREAM DINNERS   \n",
      "1   FA0056432          #1 CAFE  PR0045100          #1 CAFE   \n",
      "2   FA0241857    LAUREL TAVERN  PR0189987    LAUREL TAVERN   \n",
      "3   FA0262822  10 SPEED COFFEE  PR0213623  10 SPEED COFFEE   \n",
      "4   FA0158893           10 - E  PR0146972           10 - E   \n",
      "\n",
      "   PROGRAM ELEMENT (PE)                  PE DESCRIPTION  \\\n",
      "0                  1631  RESTAURANT SEATS MODERATE RISK   \n",
      "1                  1632      RESTAURANT SEATS HIGH RISK   \n",
      "2                  1638      RESTAURANT SEATS HIGH RISK   \n",
      "3                  1631  RESTAURANT SEATS MODERATE RISK   \n",
      "4                  1638      RESTAURANT SEATS HIGH RISK   \n",
      "\n",
      "                    FACILITY ADDRESS      FACILITY CITY FACILITY STATE  \\\n",
      "0            22226 PALOS VERDES BLVD           TORRANCE             CA   \n",
      "1        2080 CENTURY PARK E STE 108        LOS ANGELES             CA   \n",
      "2                   1220 HERMOSA AVE      HERMOSA BEACH             CA   \n",
      "3  1919 SANTA&#160;MONICA BLVD # 102  SANTA&#160;MONICA             CA   \n",
      "4                       811 W 7TH ST        LOS ANGELES             CA   \n",
      "\n",
      "  FACILITY ZIP  ...                      OWNER ADDRESS         OWNER CITY  \\\n",
      "0        90505  ...            22226   PALOS VERDES BL           TORRANCE   \n",
      "1        90067  ...          2080 CENTURY PARK E # 108        LOS ANGELES   \n",
      "2        90254  ...                   1220 HERMOSA AVE      HERMOSA BEACH   \n",
      "3        90404  ...  1919 SANTA&#160;MONICA BLVD # 102  SANTA&#160;MONICA   \n",
      "4        90017  ...                       811 W 7TH ST        LOS ANGELES   \n",
      "\n",
      "  OWNER STATE OWNER ZIP                          LOCATION CENSUS TRACTS 2010  \\\n",
      "0          CA     90505  (33.8261519457, -118.3688319755)              820.0   \n",
      "1          CA     90067  (34.0587577891, -118.4121459614)              660.0   \n",
      "2          CA     90254  (33.8624779341, -118.3999885065)              648.0   \n",
      "3          CA     90404  (34.0284451418, -118.4803289778)              441.0   \n",
      "4          CA     90017    (34.0490811348, -118.25910644)              709.0   \n",
      "\n",
      "  2011 SUPERVISORIAL DISTRICT BOUNDARIES (OFFICIAL)  \\\n",
      "0                                               4.0   \n",
      "1                                               3.0   \n",
      "2                                               4.0   \n",
      "3                                               3.0   \n",
      "4                                               1.0   \n",
      "\n",
      "  BOARD APPROVED STATISTICAL AREAS ZIP CODES  SEATING  \n",
      "0                            102.0     25719     0-30  \n",
      "1                            265.0     24032     0-30  \n",
      "2                            310.0     24688   61-150  \n",
      "3                             93.0     25713     0-30  \n",
      "4                            343.0     23078   61-150  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "...10% Dropping empty cells\n",
      "...30% Stripping spaces\n",
      "...40% Converting all to uppercase\n",
      "...100%\n",
      "  SERIAL NUMBER   VIOLATION STATUS VIOLATION CODE  \\\n",
      "0     DA0004KIJ  OUT OF COMPLIANCE           F049   \n",
      "1     DA0004KIJ  OUT OF COMPLIANCE           F042   \n",
      "2     DA0004KIJ  OUT OF COMPLIANCE           F037   \n",
      "3     DA0004KIJ  OUT OF COMPLIANCE           F015   \n",
      "4     DA0004KIJ  OUT OF COMPLIANCE           F006   \n",
      "\n",
      "                               VIOLATION DESCRIPTION  POINTS  \n",
      "0  # 50. Impoundment of unsanitary equipment or food       0  \n",
      "1  # 42. Toilet facilities: properly constructed,...       1  \n",
      "2  # 37. Adequate ventilation and lighting; desig...       1  \n",
      "3           # 15. Food obtained from approved source       2  \n",
      "4  # 06. Adequate handwashing facilities supplied...       2  \n",
      "...10% Dropping empty cells\n",
      "...30% Stripping spaces\n",
      "...40% Converting all to uppercase\n",
      "...60% Slicing out & cleaning seating column\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-af56d26ca6ff>:284: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['PE DESCRIPTION'] = df['PE DESCRIPTION'].str.replace(r\" \\(.*\\)\",\"\") # print(pe_list)\n",
      "<ipython-input-3-af56d26ca6ff>:291: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['SEATING'] = df['SEATING'].str.replace('[a-zA-Z,. ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...70% Converting to correct data types\n",
      "...80% Cleaning last bits\n",
      "...90% Formatting dates\n",
      "...100%\n",
      "  ACTIVITY DATE   OWNER ID   OWNER NAME FACILITY ID  FACILITY NAME  RECORD ID  \\\n",
      "0    2018-08-23  OW0000809           31   FA0019645  DREAM DINNERS  PR0045642   \n",
      "1    2017-12-06  OW0000809           31   FA0019645  DREAM DINNERS  PR0045642   \n",
      "2    2017-06-23  OW0000809           31   FA0019645  DREAM DINNERS  PR0045642   \n",
      "3    2019-03-19  OW0000809           31   FA0019645  DREAM DINNERS  PR0045642   \n",
      "4    2018-03-01  OW0000002  #1 CAFE INC   FA0056432        #1 CAFE  PR0045100   \n",
      "\n",
      "    PROGRAM NAME PROGRAM STATUS  PROGRAM ELEMENT (PE)  \\\n",
      "0  DREAM DINNERS         ACTIVE                  1631   \n",
      "1  DREAM DINNERS         ACTIVE                  1631   \n",
      "2  DREAM DINNERS         ACTIVE                  1631   \n",
      "3  DREAM DINNERS         ACTIVE                  1631   \n",
      "4        #1 CAFE         ACTIVE                  1632   \n",
      "\n",
      "                   PE DESCRIPTION  ... SCORE GRADE SERIAL NUMBER EMPLOYEE ID  \\\n",
      "0  RESTAURANT SEATS MODERATE RISK  ...    97     A     DA2FXQNN6   EE0000126   \n",
      "1  RESTAURANT SEATS MODERATE RISK  ...    95     A     DACP43IQW   EE0000126   \n",
      "2  RESTAURANT SEATS MODERATE RISK  ...    96     A     DAEMVMRBY   EE0000126   \n",
      "3  RESTAURANT SEATS MODERATE RISK  ...    96     A     DANER68S4   EE0000126   \n",
      "4      RESTAURANT SEATS HIGH RISK  ...    90     A     DACZXQ74W   EE0000015   \n",
      "\n",
      "                        LOCATION  \\\n",
      "0   POINT (-118.36927 33.826754)   \n",
      "1   POINT (-118.36927 33.826754)   \n",
      "2   POINT (-118.36927 33.826754)   \n",
      "3   POINT (-118.36927 33.826754)   \n",
      "4  POINT (-118.412323 34.058815)   \n",
      "\n",
      "  2011 SUPERVISORIAL DISTRICT BOUNDARIES (OFFICIAL)  CENSUS TRACTS 2010  \\\n",
      "0                                               4.0               820.0   \n",
      "1                                               4.0               820.0   \n",
      "2                                               4.0               820.0   \n",
      "3                                               4.0               820.0   \n",
      "4                                               3.0               660.0   \n",
      "\n",
      "  BOARD APPROVED STATISTICAL AREAS ZIP CODES SEATING  \n",
      "0                            102.0     25719    0-30  \n",
      "1                            102.0     25719    0-30  \n",
      "2                            102.0     25719    0-30  \n",
      "3                            102.0     25719    0-30  \n",
      "4                            265.0     24032    0-30  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "       ACTIVITY DATE FACILITY ID SERIAL NUMBER PROGRAM STATUS  SCORE SEATING  \\\n",
      "0         2018-08-23   FA0019645     DA2FXQNN6         ACTIVE     97    0-30   \n",
      "1         2017-12-06   FA0019645     DACP43IQW         ACTIVE     95    0-30   \n",
      "2         2017-06-23   FA0019645     DAEMVMRBY         ACTIVE     96    0-30   \n",
      "3         2019-03-19   FA0019645     DANER68S4         ACTIVE     96    0-30   \n",
      "4         2018-03-01   FA0056432     DACZXQ74W         ACTIVE     90    0-30   \n",
      "...              ...         ...           ...            ...    ...     ...   \n",
      "206456    2018-05-08   FA0245050     DAVWHZQ6H         ACTIVE     92   31-60   \n",
      "206457    2018-06-11   FA0259095     DA8NKGALA         ACTIVE     92   31-60   \n",
      "206458    2018-08-08   FA0259095     DAOZVOL00         ACTIVE     92   31-60   \n",
      "206459    2019-03-26   FA0259095     DAUURWY0A         ACTIVE     96   31-60   \n",
      "206460    2018-11-05   FA0259095     DAXXA067N         ACTIVE     91   31-60   \n",
      "\n",
      "                        PE DESCRIPTION  \n",
      "0       RESTAURANT SEATS MODERATE RISK  \n",
      "1       RESTAURANT SEATS MODERATE RISK  \n",
      "2       RESTAURANT SEATS MODERATE RISK  \n",
      "3       RESTAURANT SEATS MODERATE RISK  \n",
      "4           RESTAURANT SEATS HIGH RISK  \n",
      "...                                ...  \n",
      "206456      RESTAURANT SEATS HIGH RISK  \n",
      "206457      RESTAURANT SEATS HIGH RISK  \n",
      "206458      RESTAURANT SEATS HIGH RISK  \n",
      "206459      RESTAURANT SEATS HIGH RISK  \n",
      "206460      RESTAURANT SEATS HIGH RISK  \n",
      "\n",
      "[191906 rows x 7 columns]       FACILITY ID  ZIP CODES\n",
      "0       FA0019645      25719\n",
      "1       FA0056432      24032\n",
      "2       FA0241857      24688\n",
      "3       FA0262822      25713\n",
      "4       FA0158893      23078\n",
      "...           ...        ...\n",
      "40611   FA0268931       2838\n",
      "40612   FA0177854      23672\n",
      "40613   FA0160087      22722\n",
      "40614   FA0245050      23679\n",
      "40615   FA0259095       9325\n",
      "\n",
      "[40561 rows x 2 columns]   ACTIVITY DATE FACILITY ID SERIAL NUMBER PROGRAM STATUS  SCORE SEATING  \\\n",
      "0    2018-08-23   FA0019645     DA2FXQNN6         ACTIVE     97    0-30   \n",
      "1    2017-12-06   FA0019645     DACP43IQW         ACTIVE     95    0-30   \n",
      "2    2017-06-23   FA0019645     DAEMVMRBY         ACTIVE     96    0-30   \n",
      "3    2019-03-19   FA0019645     DANER68S4         ACTIVE     96    0-30   \n",
      "4    2018-03-01   FA0056432     DACZXQ74W         ACTIVE     90    0-30   \n",
      "5    2018-10-18   FA0056432     DAI7C9HIN         ACTIVE     92    0-30   \n",
      "6    2017-02-09   FA0056432     DAJFACZWZ         ACTIVE     90    0-30   \n",
      "7    2019-02-26   FA0056432     DAJLC38XH         ACTIVE     90    0-30   \n",
      "8    2017-09-06   FA0056432     DAKGVAKK1         ACTIVE     90    0-30   \n",
      "9    2016-12-28   FA0241857     DA3Y2RGMJ         ACTIVE     95  61-150   \n",
      "\n",
      "                   PE DESCRIPTION  ZIP CODES  \n",
      "0  RESTAURANT SEATS MODERATE RISK      25719  \n",
      "1  RESTAURANT SEATS MODERATE RISK      25719  \n",
      "2  RESTAURANT SEATS MODERATE RISK      25719  \n",
      "3  RESTAURANT SEATS MODERATE RISK      25719  \n",
      "4      RESTAURANT SEATS HIGH RISK      24032  \n",
      "5      RESTAURANT SEATS HIGH RISK      24032  \n",
      "6      RESTAURANT SEATS HIGH RISK      24032  \n",
      "7      RESTAURANT SEATS HIGH RISK      24032  \n",
      "8      RESTAURANT SEATS HIGH RISK      24032  \n",
      "9      RESTAURANT SEATS HIGH RISK      24688  \n",
      "        ACTIVITY DATE FACILITY ID SERIAL NUMBER PROGRAM STATUS  SCORE SEATING  \\\n",
      "0          2018-08-23   FA0019645     DA2FXQNN6         ACTIVE     97    0-30   \n",
      "1          2018-08-23   FA0019645     DA2FXQNN6         ACTIVE     97    0-30   \n",
      "2          2018-08-23   FA0019645     DA2FXQNN6         ACTIVE     97    0-30   \n",
      "3          2017-12-06   FA0019645     DACP43IQW         ACTIVE     95    0-30   \n",
      "4          2017-12-06   FA0019645     DACP43IQW         ACTIVE     95    0-30   \n",
      "...               ...         ...           ...            ...    ...     ...   \n",
      "1177518    2018-11-05   FA0259095     DAXXA067N         ACTIVE     91   31-60   \n",
      "1177519    2018-11-05   FA0259095     DAXXA067N         ACTIVE     91   31-60   \n",
      "1177520    2018-11-05   FA0259095     DAXXA067N         ACTIVE     91   31-60   \n",
      "1177521    2018-11-05   FA0259095     DAXXA067N         ACTIVE     91   31-60   \n",
      "1177522    2018-11-05   FA0259095     DAXXA067N         ACTIVE     91   31-60   \n",
      "\n",
      "                         PE DESCRIPTION  ZIP CODES VIOLATION CODE  \n",
      "0        RESTAURANT SEATS MODERATE RISK      25719           F048  \n",
      "1        RESTAURANT SEATS MODERATE RISK      25719           F046  \n",
      "2        RESTAURANT SEATS MODERATE RISK      25719           F033  \n",
      "3        RESTAURANT SEATS MODERATE RISK      25719           F048  \n",
      "4        RESTAURANT SEATS MODERATE RISK      25719           F044  \n",
      "...                                 ...        ...            ...  \n",
      "1177518      RESTAURANT SEATS HIGH RISK       9325           F040  \n",
      "1177519      RESTAURANT SEATS HIGH RISK       9325           F033  \n",
      "1177520      RESTAURANT SEATS HIGH RISK       9325           F026  \n",
      "1177521      RESTAURANT SEATS HIGH RISK       9325           F025  \n",
      "1177522      RESTAURANT SEATS HIGH RISK       9325           F014  \n",
      "\n",
      "[1177523 rows x 9 columns]\n",
      "...30% Removing inactive accounts\n",
      "...60% Formatting dates\n",
      "...90% Drop duplicates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-af56d26ca6ff>:331: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['ACTIVITY DATE'] = df['ACTIVITY DATE'].dt.year\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ACTIVITY DATE FACILITY ID SERIAL NUMBER PROGRAM STATUS  SCORE SEATING  \\\n",
      "2            2018   FA0019645     DA2FXQNN6         ACTIVE     97    0-30   \n",
      "7            2017   FA0019645     DACP43IQW         ACTIVE     95    0-30   \n",
      "11           2017   FA0019645     DAEMVMRBY         ACTIVE     96    0-30   \n",
      "15           2019   FA0019645     DANER68S4         ACTIVE     96    0-30   \n",
      "24           2018   FA0056432     DACZXQ74W         ACTIVE     90    0-30   \n",
      "\n",
      "                    PE DESCRIPTION  ZIP CODES VIOLATION CODE  \n",
      "2   RESTAURANT SEATS MODERATE RISK      25719           F033  \n",
      "7   RESTAURANT SEATS MODERATE RISK      25719           F034  \n",
      "11  RESTAURANT SEATS MODERATE RISK      25719           F033  \n",
      "15  RESTAURANT SEATS MODERATE RISK      25719           F033  \n",
      "24      RESTAURANT SEATS HIGH RISK      24032           F007  \n",
      "There is a problem with your files please check before exporting!\n",
      "Sorry no such file or directory found please try again.\n",
      "...10% Dropping empty cells\n",
      "...30% Stripping spaces\n",
      "...40% Converting all to uppercase\n",
      "...60% Slicing out & cleaning seating column\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-af56d26ca6ff>:284: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['PE DESCRIPTION'] = df['PE DESCRIPTION'].str.replace(r\" \\(.*\\)\",\"\") # print(pe_list)\n",
      "<ipython-input-3-af56d26ca6ff>:291: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['SEATING'] = df['SEATING'].str.replace('[a-zA-Z,. ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...80% Cleaning last bits\n",
      "...100%\n",
      "  FACILITY ID    FACILITY NAME  RECORD ID     PROGRAM NAME  \\\n",
      "0   FA0019645    DREAM DINNERS  PR0045642    DREAM DINNERS   \n",
      "1   FA0056432          #1 CAFE  PR0045100          #1 CAFE   \n",
      "2   FA0241857    LAUREL TAVERN  PR0189987    LAUREL TAVERN   \n",
      "3   FA0262822  10 SPEED COFFEE  PR0213623  10 SPEED COFFEE   \n",
      "4   FA0158893           10 - E  PR0146972           10 - E   \n",
      "\n",
      "   PROGRAM ELEMENT (PE)                  PE DESCRIPTION  \\\n",
      "0                  1631  RESTAURANT SEATS MODERATE RISK   \n",
      "1                  1632      RESTAURANT SEATS HIGH RISK   \n",
      "2                  1638      RESTAURANT SEATS HIGH RISK   \n",
      "3                  1631  RESTAURANT SEATS MODERATE RISK   \n",
      "4                  1638      RESTAURANT SEATS HIGH RISK   \n",
      "\n",
      "                    FACILITY ADDRESS      FACILITY CITY FACILITY STATE  \\\n",
      "0            22226 PALOS VERDES BLVD           TORRANCE             CA   \n",
      "1        2080 CENTURY PARK E STE 108        LOS ANGELES             CA   \n",
      "2                   1220 HERMOSA AVE      HERMOSA BEACH             CA   \n",
      "3  1919 SANTA&#160;MONICA BLVD # 102  SANTA&#160;MONICA             CA   \n",
      "4                       811 W 7TH ST        LOS ANGELES             CA   \n",
      "\n",
      "  FACILITY ZIP  ...                      OWNER ADDRESS         OWNER CITY  \\\n",
      "0        90505  ...            22226   PALOS VERDES BL           TORRANCE   \n",
      "1        90067  ...          2080 CENTURY PARK E # 108        LOS ANGELES   \n",
      "2        90254  ...                   1220 HERMOSA AVE      HERMOSA BEACH   \n",
      "3        90404  ...  1919 SANTA&#160;MONICA BLVD # 102  SANTA&#160;MONICA   \n",
      "4        90017  ...                       811 W 7TH ST        LOS ANGELES   \n",
      "\n",
      "  OWNER STATE OWNER ZIP                          LOCATION CENSUS TRACTS 2010  \\\n",
      "0          CA     90505  (33.8261519457, -118.3688319755)              820.0   \n",
      "1          CA     90067  (34.0587577891, -118.4121459614)              660.0   \n",
      "2          CA     90254  (33.8624779341, -118.3999885065)              648.0   \n",
      "3          CA     90404  (34.0284451418, -118.4803289778)              441.0   \n",
      "4          CA     90017    (34.0490811348, -118.25910644)              709.0   \n",
      "\n",
      "  2011 SUPERVISORIAL DISTRICT BOUNDARIES (OFFICIAL)  \\\n",
      "0                                               4.0   \n",
      "1                                               3.0   \n",
      "2                                               4.0   \n",
      "3                                               3.0   \n",
      "4                                               1.0   \n",
      "\n",
      "  BOARD APPROVED STATISTICAL AREAS ZIP CODES  SEATING  \n",
      "0                            102.0     25719      NaN  \n",
      "1                            265.0     24032      NaN  \n",
      "2                            310.0     24688      NaN  \n",
      "3                             93.0     25713      NaN  \n",
      "4                            343.0     23078      NaN  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "...10% Dropping empty cells\n",
      "...30% Stripping spaces\n",
      "...40% Converting all to uppercase\n",
      "...100%\n",
      "  SERIAL NUMBER   VIOLATION STATUS VIOLATION CODE  \\\n",
      "0     DA0004KIJ  OUT OF COMPLIANCE           F049   \n",
      "1     DA0004KIJ  OUT OF COMPLIANCE           F042   \n",
      "2     DA0004KIJ  OUT OF COMPLIANCE           F037   \n",
      "3     DA0004KIJ  OUT OF COMPLIANCE           F015   \n",
      "4     DA0004KIJ  OUT OF COMPLIANCE           F006   \n",
      "\n",
      "                               VIOLATION DESCRIPTION  POINTS  \n",
      "0  # 50. Impoundment of unsanitary equipment or food       0  \n",
      "1  # 42. Toilet facilities: properly constructed,...       1  \n",
      "2  # 37. Adequate ventilation and lighting; desig...       1  \n",
      "3           # 15. Food obtained from approved source       2  \n",
      "4  # 06. Adequate handwashing facilities supplied...       2  \n",
      "...10% Dropping empty cells\n",
      "...30% Stripping spaces\n",
      "...40% Converting all to uppercase\n",
      "...60% Slicing out & cleaning seating column\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-af56d26ca6ff>:284: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['PE DESCRIPTION'] = df['PE DESCRIPTION'].str.replace(r\" \\(.*\\)\",\"\") # print(pe_list)\n",
      "<ipython-input-3-af56d26ca6ff>:291: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['SEATING'] = df['SEATING'].str.replace('[a-zA-Z,. ]', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...70% Converting to correct data types\n",
      "...80% Cleaning last bits\n",
      "...90% Formatting dates\n",
      "...100%\n",
      "  ACTIVITY DATE   OWNER ID   OWNER NAME FACILITY ID  FACILITY NAME  RECORD ID  \\\n",
      "0    2018-08-23  OW0000809           31   FA0019645  DREAM DINNERS  PR0045642   \n",
      "1    2017-12-06  OW0000809           31   FA0019645  DREAM DINNERS  PR0045642   \n",
      "2    2017-06-23  OW0000809           31   FA0019645  DREAM DINNERS  PR0045642   \n",
      "3    2019-03-19  OW0000809           31   FA0019645  DREAM DINNERS  PR0045642   \n",
      "4    2018-03-01  OW0000002  #1 CAFE INC   FA0056432        #1 CAFE  PR0045100   \n",
      "\n",
      "    PROGRAM NAME PROGRAM STATUS  PROGRAM ELEMENT (PE)  \\\n",
      "0  DREAM DINNERS         ACTIVE                  1631   \n",
      "1  DREAM DINNERS         ACTIVE                  1631   \n",
      "2  DREAM DINNERS         ACTIVE                  1631   \n",
      "3  DREAM DINNERS         ACTIVE                  1631   \n",
      "4        #1 CAFE         ACTIVE                  1632   \n",
      "\n",
      "                   PE DESCRIPTION  ... SCORE GRADE SERIAL NUMBER EMPLOYEE ID  \\\n",
      "0  RESTAURANT SEATS MODERATE RISK  ...    97     A     DA2FXQNN6   EE0000126   \n",
      "1  RESTAURANT SEATS MODERATE RISK  ...    95     A     DACP43IQW   EE0000126   \n",
      "2  RESTAURANT SEATS MODERATE RISK  ...    96     A     DAEMVMRBY   EE0000126   \n",
      "3  RESTAURANT SEATS MODERATE RISK  ...    96     A     DANER68S4   EE0000126   \n",
      "4      RESTAURANT SEATS HIGH RISK  ...    90     A     DACZXQ74W   EE0000015   \n",
      "\n",
      "                        LOCATION  \\\n",
      "0   POINT (-118.36927 33.826754)   \n",
      "1   POINT (-118.36927 33.826754)   \n",
      "2   POINT (-118.36927 33.826754)   \n",
      "3   POINT (-118.36927 33.826754)   \n",
      "4  POINT (-118.412323 34.058815)   \n",
      "\n",
      "  2011 SUPERVISORIAL DISTRICT BOUNDARIES (OFFICIAL)  CENSUS TRACTS 2010  \\\n",
      "0                                               4.0               820.0   \n",
      "1                                               4.0               820.0   \n",
      "2                                               4.0               820.0   \n",
      "3                                               4.0               820.0   \n",
      "4                                               3.0               660.0   \n",
      "\n",
      "  BOARD APPROVED STATISTICAL AREAS ZIP CODES SEATING  \n",
      "0                            102.0     25719     NaN  \n",
      "1                            102.0     25719     NaN  \n",
      "2                            102.0     25719     NaN  \n",
      "3                            102.0     25719     NaN  \n",
      "4                            265.0     24032     NaN  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "       ACTIVITY DATE FACILITY ID SERIAL NUMBER PROGRAM STATUS  SCORE SEATING  \\\n",
      "0         2018-08-23   FA0019645     DA2FXQNN6         ACTIVE     97     NaN   \n",
      "1         2017-12-06   FA0019645     DACP43IQW         ACTIVE     95     NaN   \n",
      "2         2017-06-23   FA0019645     DAEMVMRBY         ACTIVE     96     NaN   \n",
      "3         2019-03-19   FA0019645     DANER68S4         ACTIVE     96     NaN   \n",
      "4         2018-03-01   FA0056432     DACZXQ74W         ACTIVE     90     NaN   \n",
      "...              ...         ...           ...            ...    ...     ...   \n",
      "206456    2018-05-08   FA0245050     DAVWHZQ6H         ACTIVE     92     NaN   \n",
      "206457    2018-06-11   FA0259095     DA8NKGALA         ACTIVE     92     NaN   \n",
      "206458    2018-08-08   FA0259095     DAOZVOL00         ACTIVE     92     NaN   \n",
      "206459    2019-03-26   FA0259095     DAUURWY0A         ACTIVE     96     NaN   \n",
      "206460    2018-11-05   FA0259095     DAXXA067N         ACTIVE     91     NaN   \n",
      "\n",
      "                        PE DESCRIPTION  \n",
      "0       RESTAURANT SEATS MODERATE RISK  \n",
      "1       RESTAURANT SEATS MODERATE RISK  \n",
      "2       RESTAURANT SEATS MODERATE RISK  \n",
      "3       RESTAURANT SEATS MODERATE RISK  \n",
      "4           RESTAURANT SEATS HIGH RISK  \n",
      "...                                ...  \n",
      "206456      RESTAURANT SEATS HIGH RISK  \n",
      "206457      RESTAURANT SEATS HIGH RISK  \n",
      "206458      RESTAURANT SEATS HIGH RISK  \n",
      "206459      RESTAURANT SEATS HIGH RISK  \n",
      "206460      RESTAURANT SEATS HIGH RISK  \n",
      "\n",
      "[191894 rows x 7 columns]       FACILITY ID  ZIP CODES\n",
      "0       FA0019645      25719\n",
      "1       FA0056432      24032\n",
      "2       FA0241857      24688\n",
      "3       FA0262822      25713\n",
      "4       FA0158893      23078\n",
      "...           ...        ...\n",
      "40611   FA0268931       2838\n",
      "40612   FA0177854      23672\n",
      "40613   FA0160087      22722\n",
      "40614   FA0245050      23679\n",
      "40615   FA0259095       9325\n",
      "\n",
      "[40561 rows x 2 columns]   ACTIVITY DATE FACILITY ID SERIAL NUMBER PROGRAM STATUS  SCORE SEATING  \\\n",
      "0    2018-08-23   FA0019645     DA2FXQNN6         ACTIVE     97     NaN   \n",
      "1    2017-12-06   FA0019645     DACP43IQW         ACTIVE     95     NaN   \n",
      "2    2017-06-23   FA0019645     DAEMVMRBY         ACTIVE     96     NaN   \n",
      "3    2019-03-19   FA0019645     DANER68S4         ACTIVE     96     NaN   \n",
      "4    2018-03-01   FA0056432     DACZXQ74W         ACTIVE     90     NaN   \n",
      "5    2018-10-18   FA0056432     DAI7C9HIN         ACTIVE     92     NaN   \n",
      "6    2017-02-09   FA0056432     DAJFACZWZ         ACTIVE     90     NaN   \n",
      "7    2019-02-26   FA0056432     DAJLC38XH         ACTIVE     90     NaN   \n",
      "8    2017-09-06   FA0056432     DAKGVAKK1         ACTIVE     90     NaN   \n",
      "9    2016-12-28   FA0241857     DA3Y2RGMJ         ACTIVE     95     NaN   \n",
      "\n",
      "                   PE DESCRIPTION  ZIP CODES  \n",
      "0  RESTAURANT SEATS MODERATE RISK      25719  \n",
      "1  RESTAURANT SEATS MODERATE RISK      25719  \n",
      "2  RESTAURANT SEATS MODERATE RISK      25719  \n",
      "3  RESTAURANT SEATS MODERATE RISK      25719  \n",
      "4      RESTAURANT SEATS HIGH RISK      24032  \n",
      "5      RESTAURANT SEATS HIGH RISK      24032  \n",
      "6      RESTAURANT SEATS HIGH RISK      24032  \n",
      "7      RESTAURANT SEATS HIGH RISK      24032  \n",
      "8      RESTAURANT SEATS HIGH RISK      24032  \n",
      "9      RESTAURANT SEATS HIGH RISK      24688  \n",
      "        ACTIVITY DATE FACILITY ID SERIAL NUMBER PROGRAM STATUS  SCORE SEATING  \\\n",
      "0          2018-08-23   FA0019645     DA2FXQNN6         ACTIVE     97     NaN   \n",
      "1          2018-08-23   FA0019645     DA2FXQNN6         ACTIVE     97     NaN   \n",
      "2          2018-08-23   FA0019645     DA2FXQNN6         ACTIVE     97     NaN   \n",
      "3          2017-12-06   FA0019645     DACP43IQW         ACTIVE     95     NaN   \n",
      "4          2017-12-06   FA0019645     DACP43IQW         ACTIVE     95     NaN   \n",
      "...               ...         ...           ...            ...    ...     ...   \n",
      "1177518    2018-11-05   FA0259095     DAXXA067N         ACTIVE     91     NaN   \n",
      "1177519    2018-11-05   FA0259095     DAXXA067N         ACTIVE     91     NaN   \n",
      "1177520    2018-11-05   FA0259095     DAXXA067N         ACTIVE     91     NaN   \n",
      "1177521    2018-11-05   FA0259095     DAXXA067N         ACTIVE     91     NaN   \n",
      "1177522    2018-11-05   FA0259095     DAXXA067N         ACTIVE     91     NaN   \n",
      "\n",
      "                         PE DESCRIPTION  ZIP CODES VIOLATION CODE  \n",
      "0        RESTAURANT SEATS MODERATE RISK      25719           F048  \n",
      "1        RESTAURANT SEATS MODERATE RISK      25719           F046  \n",
      "2        RESTAURANT SEATS MODERATE RISK      25719           F033  \n",
      "3        RESTAURANT SEATS MODERATE RISK      25719           F048  \n",
      "4        RESTAURANT SEATS MODERATE RISK      25719           F044  \n",
      "...                                 ...        ...            ...  \n",
      "1177518      RESTAURANT SEATS HIGH RISK       9325           F040  \n",
      "1177519      RESTAURANT SEATS HIGH RISK       9325           F033  \n",
      "1177520      RESTAURANT SEATS HIGH RISK       9325           F026  \n",
      "1177521      RESTAURANT SEATS HIGH RISK       9325           F025  \n",
      "1177522      RESTAURANT SEATS HIGH RISK       9325           F014  \n",
      "\n",
      "[1177523 rows x 9 columns]\n",
      "...30% Removing inactive accounts\n",
      "...60% Formatting dates\n",
      "...90% Drop duplicates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-af56d26ca6ff>:331: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['ACTIVITY DATE'] = df['ACTIVITY DATE'].dt.year\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ACTIVITY DATE FACILITY ID SERIAL NUMBER PROGRAM STATUS  SCORE SEATING  \\\n",
      "2            2018   FA0019645     DA2FXQNN6         ACTIVE     97     NaN   \n",
      "7            2017   FA0019645     DACP43IQW         ACTIVE     95     NaN   \n",
      "11           2017   FA0019645     DAEMVMRBY         ACTIVE     96     NaN   \n",
      "15           2019   FA0019645     DANER68S4         ACTIVE     96     NaN   \n",
      "24           2018   FA0056432     DACZXQ74W         ACTIVE     90     NaN   \n",
      "\n",
      "                    PE DESCRIPTION  ZIP CODES VIOLATION CODE  \n",
      "2   RESTAURANT SEATS MODERATE RISK      25719           F033  \n",
      "7   RESTAURANT SEATS MODERATE RISK      25719           F034  \n",
      "11  RESTAURANT SEATS MODERATE RISK      25719           F033  \n",
      "15  RESTAURANT SEATS MODERATE RISK      25719           F033  \n",
      "24      RESTAURANT SEATS HIGH RISK      24032           F007  \n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.cbook as cbook\n",
    "import json, os\n",
    "from tkinter import ttk\n",
    "from tkinter import *\n",
    "from tkinter.filedialog import asksaveasfile \n",
    "from tkinter.filedialog import asksaveasfilename\n",
    "from tkinter import filedialog\n",
    "from tkinter import messagebox\n",
    "from datetime import datetime\n",
    "\n",
    "# ------ GLOBAL VARIABLES ------ #\n",
    "\n",
    "# Change missing values to NaN for consistency\n",
    "missing_values = [\"NA\", \"N/A\", \"na\", r\"^\\s*$\", \"\", \" \", \"NaN\"]\n",
    "# counts value then finds the one that appears the most time (mode)\n",
    "df1_mode =  lambda x:x.value_counts().index[0]\n",
    "# Changes to true once file clean has been done at least once\n",
    "file_cleaned = False\n",
    "# creating instance of Tk class\n",
    "window = tk.Tk()\n",
    "window.title(\"DATA ANALYSIS TOOL\")\n",
    "\n",
    "# disable windows from resizing\n",
    "window.resizable(False, False)  \n",
    "\n",
    "# window sizing\n",
    "window_height = 450\n",
    "window_width = 500\n",
    "screen_width = window.winfo_screenwidth()\n",
    "screen_height = window.winfo_screenheight()\n",
    "\n",
    "# Places window in middle of screen\n",
    "x_cordinate = int((screen_width/2) - (window_width/2))\n",
    "y_cordinate = int((screen_height/2) - (window_height/2))\n",
    "window.geometry(\"{}x{}+{}+{}\".format(window_width, window_height, x_cordinate, y_cordinate))\n",
    "\n",
    "\n",
    "# Adding Tabs to window \n",
    "tab_control = ttk.Notebook(window)\n",
    "cleaning_tab = ttk.Frame(tab_control)\n",
    "graph_tab = ttk.Frame(tab_control)\n",
    "\n",
    "# Adding text to tab and styling \n",
    "tab_control.add(cleaning_tab, text=\"1. Clean Data\")\n",
    "tab_control.add(graph_tab, text=\"2. Generate Graph\")\n",
    "tab_control.pack(expand=1, fill=\"both\")\n",
    "\n",
    "\n",
    "# ----- STATUS BAR ---- #\n",
    "status_text = StringVar(window)\n",
    "status_text.set(\"[TIP] Please load your files by clicking the browse button(s).\")\n",
    "status_bar = Label(window, textvariable=status_text, bd=1, relief=tk.SUNKEN, font=('Helvetica', 12, 'normal'))\n",
    "status_bar.configure(foreground='green')\n",
    "status_bar.pack(side=BOTTOM, fill=X)\n",
    "status_bar.config(background='#F9F9F9', relief = RAISED, height = 2)\n",
    "\n",
    "# ------ STYLING ------ #\n",
    "\n",
    "# Default text\n",
    "style = ttk.Style()\n",
    "style.configure(\n",
    "    \"STD.Label\",\n",
    "    foreground=\"#666\",\n",
    "    font=\"Helvetica\",\n",
    "    fontsize=8\n",
    ")\n",
    "\n",
    "# ---- NEW HEADERS ---- # \n",
    "\n",
    "\n",
    "# Inventory (df1)\n",
    "inventory_headers = [\"FACILITY ID\", \"ZIP CODES\"]\n",
    "# Violation (df2)\n",
    "violation_headers = ['SERIAL NUMBER', 'VIOLATION CODE']\n",
    "# Inspection (df3)\n",
    "inspection_headers = [\"ACTIVITY DATE\", \"FACILITY ID\", \"SERIAL NUMBER\", \"PROGRAM STATUS\", \"SCORE\", \"SEATING\", \"PE DESCRIPTION\"]\n",
    "\n",
    "\n",
    "# ---- FUNCTIONS ---- #\n",
    "\n",
    "\n",
    "# ---- STATUS MESSAGES ---- #\n",
    "\n",
    " \n",
    "def status_preparing():\n",
    "    status_bar.configure(foreground='green')\n",
    "    status_text.set(\"[STATUS] Preparing to clean loaded files...\")\n",
    "\n",
    "def status_cleaned():\n",
    "    status_bar.configure(foreground='green')\n",
    "    status_text.set(\"[SUCCESS] You have cleaned the files now please export/save the file!\")\n",
    "\n",
    "def status_exported():\n",
    "    status_text.set(\"[SUCCESS[ You have exported your new data files!\")\n",
    "    status_bar.configure(foreground='green')\n",
    "\n",
    "\n",
    "def status_okay():\n",
    "    status_bar.configure(foreground='green')\n",
    "    status_text.set(\"[SUCCESS] all files cleaned!\")\n",
    "\n",
    "def error_files():\n",
    "    status_bar.configure(foreground='red')\n",
    "    status_text.set('[ERROR] There is a problem with your file(s) please check before exporting!')\n",
    "    print(\"There is a problem with your files please check before exporting!\")\n",
    "\n",
    "def status_illegal():\n",
    "    status_bar.configure(foreground='red')\n",
    "    status_text.set('[ERROR] You have just commited an illegal actiob')\n",
    "    print(\"You have not loaded or cleaned your files to export yet!\")\n",
    "\n",
    "def error_location():\n",
    "    status_bar.configure(foreground='red')\n",
    "    status_text.set('[ERROR] Please load valid location for the data file by clicking browse.')\n",
    "\n",
    "\n",
    "# ----- SAVE ----- #\n",
    "\n",
    "def save():\n",
    "    # file = askopenfilename(filetypes=((\"JSON files\", \"*.json\"),(\"All files\", \"*.*\") ))\n",
    "    # checks if file has been cleaned and if the fields contain text\n",
    "    if (file_cleaned == True ) and (len(input_inspections.get()) != 0) and (len(input_inventory.get()) != 0) and (len(input_violations.get()) != 0):\n",
    "        global savefile\n",
    "        savefile = asksaveasfilename(filetypes=((\"JSON files\", \"*.json\"),\n",
    "                                            (\"All files\", \"*.*\") ))    \n",
    "    else:\n",
    "        error_files()\n",
    "\n",
    "    try:\n",
    "        data = df4_cleaned\n",
    "        data.to_json(savefile, index='true')   \n",
    "        status_text.set('You have saved your file.')\n",
    "      \n",
    "    except NameError:\n",
    "        error_files()\n",
    "        print(\"Failed to export file\\n'%s'\" % savefile, \"Please check you uploaded the files correctly.\")\n",
    "    except FileNotFoundError:\n",
    "        error_files()\n",
    "        print(\"Sorry no such file or directory found please try again.\")\n",
    "    \n",
    "\n",
    "# ---- EXPORT TO JSON ---- #\n",
    "\n",
    "\n",
    "def export_json(file):\n",
    "\n",
    "    global status_bar, new_json_name, file_name\n",
    "\n",
    "    file_name = \"facilities\"\n",
    "\n",
    "    if len(input_filename.get()) != 0:\n",
    "        file_name = input_filename.get()\n",
    "    else: \n",
    "        file_name = \"facilities\"\n",
    "\n",
    "    try:\n",
    "        # New json name\n",
    "        new_json_name = file_name + \".json\"\n",
    "        file.to_json(new_json_name, index='true') \n",
    "        status_exported()  \n",
    "\n",
    "    except NameError:\n",
    "        error_files() \n",
    "\n",
    "\n",
    "# ------ EXIT ------ #\n",
    "\n",
    "def exit():\n",
    "\n",
    "    if messagebox.askokcancel(\"Exit Program\", \"Have you saved out the cleaned file? Clicking okay exits the program.\"):\n",
    "        window.destroy()\n",
    "\n",
    "    \n",
    "# ----- UPLOAD/BROWSE FOR FILES ----- #\n",
    "\n",
    "\n",
    "# Browse inventory file to upload function\n",
    "def open_file1():\n",
    "    global df_inventory, status_bar\n",
    "\n",
    "    try:\n",
    "        # Open only CSV\n",
    "        file = filedialog.askopenfile(filetypes =[('Data Files', '*.csv')])\n",
    "        # Fill in missing value with NaN\n",
    "\n",
    "        df_inventory = pd.read_csv(file.name,keep_default_na=False, na_values=missing_values)\n",
    "\n",
    "        input_text = file.name\n",
    "        \n",
    "        # Update input field with file upload url\n",
    "        input_inventory.delete(0, tk.END)\n",
    "        input_inventory.insert(0, input_text)\n",
    "    except AttributeError:\n",
    "        status_bar.configure(foreground='red')\n",
    "        status_text.set('[ERROR] Please open a valid location for the Inventory file')\n",
    "        print(\"Please open a valid location for the Inventory file\")    \n",
    "   \n",
    "# Browse violation file to upload function\n",
    "def open_file2():\n",
    "    global df_violations\n",
    "\n",
    "    try:\n",
    "        file = filedialog.askopenfile(filetypes =[('Data Files', '*.csv')])\n",
    "        df_violations = pd.read_csv(file.name,keep_default_na=False, na_values=missing_values)   \n",
    "        input_text = file.name\n",
    "        # Update input field with file upload url\n",
    "        input_violations.delete(0, tk.END)\n",
    "        input_violations.insert(0, input_text)\n",
    "\n",
    "    except AttributeError:\n",
    "        status_text.set('Please open a valid location for the Violation file')\n",
    "        print(\"Please open a valid location for the Violation file\")    \n",
    "\n",
    "# Browse inspection file to upload function\n",
    "def open_file3(): \n",
    "    global df_inspections\n",
    "    try:\n",
    "\n",
    "        file = filedialog.askopenfile(filetypes =[('Data Files', '*.csv')])\n",
    "        df_inspections = pd.read_csv(file.name,keep_default_na=False, na_values=missing_values)\n",
    "        input_text = file.name\n",
    "\n",
    "        # Update input field with file upload url\n",
    "        input_inspections.delete(0, tk.END)\n",
    "        input_inspections.insert(0, input_text)\n",
    "    except AttributeError:\n",
    "        print(\"Please open a valid location for the Inspection file\")\n",
    "\n",
    "\n",
    "def open_file4(): \n",
    "    global json_file\n",
    "    try:\n",
    "\n",
    "        file = filedialog.askopenfile(filetypes =[('JSON Files', '*.json')])\n",
    "        # change this to file after \n",
    "        json_file = pd.read_json(file)\n",
    "        input_text = file.name\n",
    "\n",
    "        # Update input field with file upload url\n",
    "        input_graph.delete(0, tk.END)\n",
    "        input_graph.insert(0, input_text)\n",
    "        status_text.set('Your JSON file has been loaded.')\n",
    "\n",
    "    except AttributeError or ValueError:\n",
    "        error_location()\n",
    "        print(\"Please open a valid location for the data file\")\n",
    "\n",
    "\n",
    "# ---- FIRST CLEAN ---- #\n",
    "def generic_clean(df):\n",
    "\n",
    "    global file_cleaned\n",
    "\n",
    "    # Dropping data with over 50% null to avoid errors \n",
    "\n",
    "    print(\"...10% Dropping empty cells\")\n",
    "    df.dropna(inplace = True) \n",
    "\n",
    "    # Replace NaN, missing values etc with 0\n",
    "    df.fillna(0)\n",
    "    status_text.set(\"...20% Neatening missing values\")\n",
    "\n",
    "    status_text.set(\"...Currently cleaning files please wait\")\n",
    "    print(\"...30% Stripping spaces\")\n",
    "    # Regex finds spaces 2 or more & changes to 1 and strips space before/after \n",
    "    df.columns = [col.strip().replace('  ', ' ') for col in df.columns]\n",
    "\n",
    "    print(\"...40% Converting all to uppercase\")\n",
    "    df.columns = [x.upper() for x in df.columns]\n",
    "    # print(csv_df.columns) to check if it works :)\n",
    "\n",
    "\n",
    "    if \"PE DESCRIPTION\" in df:\n",
    "        \n",
    "        print(\"...60% Slicing out & cleaning seating column\")\n",
    "        # Seating numbers only\n",
    "        new_seat_col = df['PE DESCRIPTION'].str.extract('.*\\((.*)\\).*') # print(new_seat_col)\n",
    "\n",
    "        # Remove seating numbers leave behind rest\n",
    "        df['PE DESCRIPTION'] = df['PE DESCRIPTION'].str.replace(r\" \\(.*\\)\",\"\") # print(pe_list)\n",
    "\n",
    "        # New headers\n",
    "        df['SEATING'] = new_seat_col\n",
    "\n",
    "        # Remove Alpha, Commas, Full stop and Spacing\n",
    "\n",
    "        df['SEATING'] = df['SEATING'].str.replace('[a-zA-Z,. ]', '')\n",
    "        # '/^[a-zA-Z0-9,\\.\\s]*$/'\n",
    "        # [a-zA-Z]\n",
    "        \n",
    "    if \"SCORE\" in df:\n",
    "        print(\"...70% Converting to correct data types\")\n",
    "        df[\"SCORE\"] = df[\"SCORE\"].apply(np.int64) \n",
    "\n",
    "    if \"ZIP CODES\" in df:\n",
    "        print(\"...80% Cleaning last bits\")\n",
    "        df[\"ZIP CODES\"] = df[\"ZIP CODES\"].apply(np.int64) \n",
    "        # int_df = df[\"ZIP CODES\"].astype(int)\n",
    "\n",
    "    if \"ACTIVITY DATE\" in df:\n",
    "        print(\"...90% Formatting dates\")\n",
    "        df['ACTIVITY DATE'] =  pd.to_datetime(df['ACTIVITY DATE'], format='%m/%d/%Y')\n",
    "\n",
    "\n",
    "    print(\"...100%\")\n",
    "    \n",
    "    file_cleaned = True\n",
    "\n",
    "    print(df.head(5))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ---- SECOND CLEAN ---- #\n",
    "\n",
    "def second_clean(df):\n",
    "    \n",
    "    if \"PROGRAM STATUS\" in df:\n",
    "        print(\"...30% Removing inactive accounts\")\n",
    "        df = df[df['PROGRAM STATUS'] != 'INACTIVE']\n",
    "\n",
    "    if \"ACTIVITY DATE\" in df:\n",
    "        status_text.set(\"...Cleaning data please wait\")\n",
    "        print(\"...60% Formatting dates\")\n",
    "\n",
    "        # Turns all dates to Y (YEAR) e.g 2019-02-3 to 2019\n",
    "        df['ACTIVITY DATE'] = df['ACTIVITY DATE'].dt.year\n",
    "\n",
    "    if \"SERIAL NUMBER\" and \"FACILITY ID\" in df:\n",
    "        print(\"...90% Drop duplicates\")\n",
    "        df = df.drop_duplicates(subset=['ACTIVITY DATE', 'FACILITY ID', 'SERIAL NUMBER'], keep='last')\n",
    "    \n",
    "    status_text.set(\"...Your data have been cleaned and exported to the same folder!\")\n",
    "\n",
    "    print(df.head(5))\n",
    "\n",
    "    return df\n",
    "\n",
    "# ---- CLEAN FILE FUNCTION BUTTON ---- #\n",
    " \n",
    "def clean_files():\n",
    "    \n",
    "    global df4_cleaned\n",
    "\n",
    "    status_preparing()\n",
    "\n",
    "    # Clean & Creating new subset DataFrames\n",
    "\n",
    "    try: \n",
    "            \n",
    "        # Only clean if ALL files are present \n",
    "        if (len(input_inspections.get()) != 0) and (len(input_violations.get()) != 0) and (len(input_inventory.get()) != 0):\n",
    "\n",
    "            global df1, df2, df3\n",
    "            \n",
    "            status_okay()\n",
    "            # Clean and created subset of inventory\n",
    "            clean1 = generic_clean(df_inventory)\n",
    "            df1 = pd.DataFrame(clean1, columns=inventory_headers)\n",
    "\n",
    "            # Subset of violations with new headers (condensed )\n",
    "            clean2 = generic_clean(df_violations)\n",
    "            df2 = pd.DataFrame(clean2, columns=violation_headers)\n",
    "\n",
    "            # Subset of inspections condensed new headers \n",
    "            clean3 = generic_clean(df_inspections)\n",
    "            df3 = pd.DataFrame(clean3, columns=inspection_headers)\n",
    "\n",
    "\n",
    "            # ----MERGE INTO 1 FILE  ----- #\n",
    "\n",
    "            # merge. common columns = facility id for ZIP CODES\n",
    "            df4_merge = pd.merge(df3, df1, how='inner', on='FACILITY ID')\n",
    "\n",
    "            print(df3, df1, df4_merge.head(10))\n",
    "            # merge columns so serial number becomes the violation code \n",
    "            df4_merge2 = pd.merge(df4_merge, df2, how='inner', on='SERIAL NUMBER')\n",
    "\n",
    "            print(df4_merge2)\n",
    "\n",
    "            # print(\"SERIAL df4_merge2: \", df4_merge.loc[df4_merge['SERIAL NUMBER'] == 'DA2FXQNN6'])\n",
    "            # df4_merge2 = df4_merge2.pop('SERIAL NUMBER')\n",
    "\n",
    "            # second clean\n",
    "            df4_second = second_clean(df4_merge2)\n",
    "            df4_cleaned = df4_second.reset_index(drop=True)\n",
    "\n",
    "            export_json(df4_cleaned)\n",
    "\n",
    "\n",
    "        else:\n",
    "\n",
    "            # If 1 or more files not present goes to error\n",
    "            error_files()\n",
    "\n",
    "\n",
    "    except NameError:\n",
    "        print(\"There is an issue with one or more of your file uploads, please check them then try again.\")\n",
    "\n",
    "\n",
    "\n",
    "# ------ TABLE: SEATING MEAN, MEDIAN, MODE  ---- # \n",
    "\n",
    "def table_seating():\n",
    "        \n",
    "    # SEATING \n",
    "\n",
    "    # making grouped by activity date first, then seating\n",
    "    grouped = json_file.groupby(['ACTIVITY DATE', 'SEATING'])\n",
    "\n",
    "    # make activity date by YEAR \n",
    "    # using score to calculate\n",
    "    group_json_file= grouped['SCORE']\n",
    "\n",
    "    # Calculating Mode by using value counts then finding the first value in row\n",
    "\n",
    "    # calculating mean, median \n",
    "    df1_mean = group_json_file.agg([('MEAN', 'mean'), ('MEDIAN','median'), ('MODE', df1_mode)])\n",
    "\n",
    "    # turn mean/median/mode groupby table into DataFrame \n",
    "    df1_1 = pd.DataFrame(df1_mean)\n",
    "\n",
    "    print(df1_1)\n",
    "    return df1_1\n",
    "\n",
    "# ------ TABLE: ZIP CODE MEAN, MEDIAN, MODE ---- # \n",
    "\n",
    "def table_zip():\n",
    "\n",
    "    # making grouped by activity date first, then seating\n",
    "    grouped2 = json_file.groupby(['ACTIVITY DATE', 'ZIP CODES'])\n",
    "\n",
    "    # using score to calculate\n",
    "    group_df2 = grouped2['SCORE']\n",
    "\n",
    "    # Calculating Mode by using value counts then finding the first value in row\n",
    "\n",
    "    # calculating mean, median \n",
    "    df2_mean = group_df2.agg([('MEAN', 'mean'), ('MEDIAN','median'), ('MODE', df1_mode)])\n",
    "\n",
    "    # turn mean/median/mode groupby table into DataFrame \n",
    "    df2_1 = pd.DataFrame(df2_mean)\n",
    "\n",
    "    print(\"First 100:\\n\", df2_1.head(100))\n",
    "\n",
    "    return df2_1\n",
    "\n",
    "\n",
    "# ------ WRANGLING - TOTAL VIOLATION COUNT PER CODE ----- # \n",
    "\n",
    "def w_total():\n",
    "\n",
    "    global total_score\n",
    "    # total violations PER facility\n",
    "    total_score = json_file['VIOLATION CODE'].value_counts().reset_index() # reset index\n",
    "    total_score.columns = ['VIOLATION CODE', 'TOTAL VIOLATIONS']\n",
    "    total_score = total_score.sort_values(by=['VIOLATION CODE'])\n",
    "\n",
    "    # Remove values below this total amount\n",
    "    values_below = slider_max.get()\n",
    "    # Drop rows, keep rest \n",
    "    total_score = total_score[total_score['TOTAL VIOLATIONS'] > values_below]\n",
    "\n",
    "    print(total_score)\n",
    "    return total_score\n",
    "\n",
    "\n",
    "# ------ WRANGLING - TOTAL VIOLATION FOR ZIP CODE COMPARISON FACILITIES ----- # \n",
    "\n",
    "def w_violation_facility():\n",
    "\n",
    "    global df6, df6_str, colours\n",
    "\n",
    "    # Grab df5_merge and count up violations per facility \n",
    "    df6_count = json_file['FACILITY ID'].value_counts().reset_index()\n",
    "\n",
    "    # Total violations of each facility\n",
    "    df6_count.columns = ['FACILITY ID', 'TOTAL VIOLATIONS']\n",
    "\n",
    "    # Add total violations to end of facilities dataframe. \n",
    "    df6_merge = pd.merge(json_file, df6_count, how='inner', on='FACILITY ID')\n",
    "\n",
    "    # Groups by zip then shows total violations per facility grouped via zip code\n",
    "    df6_total = df6_merge.groupby('ZIP CODES')['FACILITY ID'].value_counts().to_frame(name = 'TOTAL VIOLATIONS').reset_index()\n",
    "\n",
    "    # std calculates variability and avg distance from mean\n",
    "    agg_group = [ ('FACILITIES', 'count'), ('VIOLATIONS', 'sum'), ('STD','std'), ('MEAN','mean'),('MEDIAN','median'), ('MODE', df1_mode), ('MIN', 'min'), ('MAX', 'max')]\n",
    "    df6_group = df6_total.groupby('ZIP CODES')['TOTAL VIOLATIONS'].agg(agg_group)\n",
    "    df6_group['RANGE'] = df6_group['MAX'] - df6_group['MIN']\n",
    "\n",
    "    # Fill in empty or NaN values as 0\n",
    "    df6_group = df6_group.fillna(0)\n",
    "\n",
    "    # Resets index and ZIP CODES is now level 0 column header\n",
    "    df6 = df6_group.reset_index()\n",
    "\n",
    "    # Random colours for graph!\n",
    "    N = df6.shape[0]\n",
    "    colours = np.random.rand(N)/2\n",
    "\n",
    "\n",
    "    # Turn zip codes into a string \n",
    "    df6_str = df6['ZIP CODES'].astype(str)\n",
    "    return df6\n",
    "\n",
    "\n",
    "    # DF6 is the final cleaned, prepped, wrangled DF to use for graphs #\n",
    "\n",
    "\n",
    "# ---- CREATE 4 TILE GRAPH ---- #\n",
    "# \n",
    "    graphs = plt.figure()\n",
    "\n",
    "def start_graphs():\n",
    "        # name graph window\n",
    "    global graphs, graph_code, graph_zip, graph_std, graph_series\n",
    "\n",
    "    graphs = plt.figure()\n",
    "    plt.title('Violation Graphs')\n",
    "    graphs.set_figwidth(13) \n",
    "    graphs.set_figheight(7) \n",
    "    # add location of subplots\n",
    "\n",
    "    graph_code = graphs.add_subplot(2, 2, 1)\n",
    "    graph_zip = graphs.add_subplot(2, 2, 2)\n",
    "    graph_std = graphs.add_subplot(2, 2, 3)\n",
    "    graph_series = graphs.add_subplot(2, 2, 4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- BAR GRAPH: TOTAL VIOLATIONS PER VIOLATION CODE ---- # \n",
    "\n",
    "def graph_total():\n",
    "\n",
    "    graph_code.bar(total_score['VIOLATION CODE'], total_score['TOTAL VIOLATIONS'], color='hotpink')\t\n",
    "    graph_code.set_xlabel('VIOLATION CODES')\n",
    "    graph_code.set_ylabel('TOTAL VIOLATIONS')\n",
    "\n",
    "    # graph_code.set_title('TOTAL VIOLATIONS FOR EACH CODE')\n",
    "\n",
    "\n",
    "# ---- SCATTER GRAPH: FOR ZIP / FACILITY / VIOLATION ---- # \n",
    "\n",
    "\n",
    "def graph_zip_fac_vio():\n",
    "\n",
    "    graph_zip.scatter(df6['FACILITIES'], df6['VIOLATIONS'], c='blue', alpha=0.3)\n",
    "\n",
    "    # Titles \n",
    "    graph_zip.set_xlabel('TOTAL FACILITIES (PER ZIP CODE)')\n",
    "    graph_zip.set_ylabel('TOTAL VIOLATIONS')\n",
    "    # graph_zip.set_title('TOTAL FACILITIES VS TOTAL VIOLATIONS PER ZIP CODE')\n",
    "\n",
    "\n",
    "# --- DRAW SCATTER GRAPH, VARYING SIZE ZIP / FACILITY / VIOLATION --- # \n",
    "\n",
    "# plot zip code on Y axis\n",
    "def graph_scatter_zip():\n",
    "    # size of each circle plotted \n",
    "    size = df6['FACILITIES']\n",
    "    graph_series.scatter(df6_str, df6['VIOLATIONS'], c=colours, s=size, alpha=0.3)\n",
    "    graph_series.set_xlabel('ZIP CODES')\n",
    "    graph_series.set_ylabel('TOTAL VIOLATIONS')\n",
    "\n",
    "\n",
    "# --- LINE GRAPH: STANDARD DEVIATION and RANGE --- # \n",
    "\n",
    "def graph_zip_stats():\n",
    "    # Violations per zip codes\n",
    "    graph_std.plot(df6_str, df6['VIOLATIONS'], color='purple', label='Total Violations')\n",
    "\n",
    "    # Total facilities per zip code\n",
    "    graph_std.plot(df6_str, df6['FACILITIES'], color='black', label='Total Facilities')\n",
    "    graph_std.plot(df6_str, df6['RANGE'], color='orange', label='Range')\n",
    "    graph_std.plot(df6_str, df6['STD'], color='green', label='Standard Deviation')\n",
    "\n",
    "    # Titles \n",
    "    graph_std.set_xlabel('ZIP CODES')\n",
    "\n",
    "    # Show labels!\n",
    "    graphs.legend(loc='lower left', bbox_to_anchor=(0, 0), shadow=True, ncol=1)\n",
    "\n",
    "\n",
    "# ------ GRAPHS FUNCTION BUTTON ---- #\n",
    "\n",
    "\n",
    "def graph_selection():\n",
    "\n",
    "    # Clear graphs \n",
    "    graphs.clear()\n",
    "    # Draw graphs\n",
    "    start_graphs()\n",
    "    # Prepare data for graphs\n",
    "    w_violation_facility()\n",
    "    w_total()\n",
    "    if graph1.get() == 1:\n",
    "        # Total violations per code\n",
    "        graph_total()\n",
    "    if graph2.get() == 1:\n",
    "        # Total Violations per Zip Code \n",
    "        graph_zip_fac_vio()\n",
    "    if graph3.get() == 1:\n",
    "        # Total Facilities vs. Total Violations (Per Zip)\n",
    "        graph_scatter_zip()\n",
    "    if graph4.get() == 1:\n",
    "        # Zip code total violation; std, mean, median, mode etc\n",
    "        graph_zip_stats()\n",
    "    if v_seat.get() == 1:\n",
    "        # Print seating mean, median mode table in terminal\n",
    "        table_seating()\n",
    "    if v_zip.get() == 1:\n",
    "        # Print zip code mean, median mode table in terminal\n",
    "        table_zip()\n",
    "    else:\n",
    "        status_text.set('No graphs have been selected. Please pick at least 1')\n",
    "\n",
    "def generate_graphs():\n",
    "\n",
    "    if len(input_graph.get()) == 0:\n",
    "        error_files()\n",
    "    else:\n",
    "        graph_selection()\n",
    "        status_text.set('[STATUS] Building your graphs! Check new window')\n",
    "        plt.show()\n",
    "    \n",
    "    # --- SHOW GRAPHS ---- # \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- EXPORT GRAPHS ----- #\n",
    "\n",
    "def export_graphs():\n",
    "\n",
    "    # Build graphs but not show\n",
    "    try: \n",
    "        graph_selection()\n",
    "        # Export as image\n",
    "        graphs.savefig('graphs.png')\n",
    "        status_text.set('Your graphs have been exported into the same folder!')\n",
    "    except NameError:\n",
    "        error_location()\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ------ TAB 1: CLEANING CONTENTS ------ #\n",
    "\n",
    "# Adding text label\n",
    "ttk.Label(cleaning_tab, text=\"Inventory File\", style=\"STD.Label\").grid(row= 1, column=0, padx=10, pady=10, sticky=W)\n",
    "ttk.Label(cleaning_tab, text=\"Violations File\", style=\"STD.Label\").grid(row= 2, column=0, padx=10, pady=10, sticky=W)\n",
    "ttk.Label(cleaning_tab, text=\"Inspections File\", style=\"STD.Label\").grid(row= 3, column=0, padx=10, pady=10, sticky=W)\n",
    "ttk.Label(cleaning_tab, text=\"Ouput File Name\", style=\"STD.Label\").grid(row=4, column=0, padx=10, pady=25, sticky=W)\n",
    "ttk.Label(cleaning_tab, text=\"Please upload your data (.csv) files to be cleaned\", style='STD.Label').grid(row=0, column=0, columnspan=3, padx=10, pady=30)\n",
    "\n",
    "# Adding input fields to cleaning_tab\n",
    "input_inventory = ttk.Entry(cleaning_tab)\n",
    "input_violations = ttk.Entry(cleaning_tab)\n",
    "input_inspections = ttk.Entry(cleaning_tab)\n",
    "input_filename = ttk.Entry(cleaning_tab)\n",
    "\n",
    "# Position of input fields\n",
    "input_inventory.grid(row=1, column=1, padx=5, pady=0)\n",
    "input_violations.grid(row=2, column=1, padx=5, pady=0)\n",
    "input_inspections.grid(row=3, column=1, padx=5, pady=0)\n",
    "input_filename.grid(row=4, column=1, padx=0, pady=0)\n",
    "\n",
    "# File Browse Buttons\n",
    "btn_browse1 = ttk.Button(cleaning_tab, text=\"Browse\", command = lambda:open_file1())\n",
    "btn_browse2 = ttk.Button(cleaning_tab, text=\"Browse\", command = lambda:open_file2())\n",
    "btn_browse3 = ttk.Button(cleaning_tab, text=\"Browse\", command = lambda:open_file3())\n",
    "# Browse button layout  \n",
    "btn_browse1.grid(row=1, column=2)\n",
    "btn_browse2.grid(row=2, column=2)\n",
    "btn_browse3.grid(row=3, column=2)\n",
    "# btn_save_json.grid(row=4, column=2)\n",
    "\n",
    "# Action Buttons\n",
    "btn_save = ttk.Button(cleaning_tab, text=\"Save As\", command= lambda:save())\n",
    "btn_clean = ttk.Button(cleaning_tab, text=\"Clean & Export\", command= lambda:clean_files())\n",
    "btn_close = ttk.Button(cleaning_tab, text=\"Close\", command=exit)\n",
    "# Action button layout\n",
    "btn_clean.grid(row=5, column=1)\n",
    "btn_save.grid(row=5, column=0, sticky=E, pady=20)\n",
    "btn_close.grid(row=5, column=2, sticky=W)\n",
    "\n",
    "# ------ TAB 2: GRAPH CONTENTS ------ #\n",
    "\n",
    "\n",
    "ttk.Label(graph_tab, text=\"Upload your cleaned data file to produce graphs for analysis\", style='STD.Label').grid(row=0, column=0, columnspan=3, padx=10, pady=20)\n",
    "\n",
    "\n",
    "# 1) Upload data file \n",
    "\n",
    "ttk.Label(graph_tab, text=\"Cleaned Data File\", style='STD.Label').grid(row=1, column=0, padx=10, pady=10, sticky=W)\n",
    "\n",
    "\n",
    "# Adding input fields to graph_tab\n",
    "input_graph = ttk.Entry(graph_tab)\n",
    "# Position of input fields\n",
    "input_graph.grid(row=1, column=1, sticky=W)\n",
    "\n",
    "# Browse button \n",
    "btn_graph_browse = ttk.Button(graph_tab, text=\"Browse\", command = lambda:open_file4())\n",
    "btn_graph_browse.grid(row=1, column=2, sticky=W)\n",
    "\n",
    "\n",
    "# 2) Select graphs \n",
    "\n",
    "ttk.Label(graph_tab, text=\"Select the visualisations you would like to generate\", style=\"STD.Label\").grid(row= 2, column=0, padx=10, pady=10, sticky=W, columnspan=3)\n",
    "\n",
    "\n",
    "# Check boxes\n",
    "v_seat = tk.IntVar()\n",
    "v_zip = tk.IntVar()\n",
    "graph1 = tk.IntVar()\n",
    "graph2 = tk.IntVar()\n",
    "graph3 = tk.IntVar()\n",
    "graph4 = tk.IntVar()\n",
    "\n",
    "# Seating Table\n",
    "check_seat=Checkbutton(graph_tab,text=\"Seating Stats\", variable=v_seat, onvalue=1, offvalue=0, background='#ececec')\n",
    "check_seat.grid(row=3,column=0, sticky=W,columnspan=2,  padx=5, pady=5)\n",
    "\n",
    "# Zip Codes Table\n",
    "check_zip=Checkbutton(graph_tab,text=\"Zip Code Stats(Terminal)\", variable=v_zip, onvalue=1, offvalue=0, background='#ececec')\n",
    "check_zip.grid(row=3,column=1, sticky=W)\n",
    "\n",
    "\n",
    "# Total violations per code\n",
    "check_total=Checkbutton(graph_tab,text=\"Total Violations For Each Violation Code\", variable=graph1, onvalue=1, offvalue=0, background='#ececec')\n",
    "check_total.grid(row=4,column=0, sticky=W, columnspan=3, padx=5)\n",
    "\n",
    "\n",
    "# Remove values between + Slider\n",
    "ttk.Label(graph_tab, text=\"Delete values below\", style=\"STD.Label\", foreground=\"#777777\").grid(row= 5, column=0, padx=10, sticky=W)\n",
    "# Add slider so they dont enter wrong values\n",
    "# max_violation = df4_cleaned['TOTAL VIOLATIONS'].agg('max')\n",
    "slider_max = Scale(graph_tab, from_=0, to=1000, orient=HORIZONTAL, bg = \"#ececec\", length=200)\n",
    "slider_max.grid(row=5, column=1, columnspan=2, sticky=W, padx=5)\n",
    "\n",
    "check_zip=Checkbutton(graph_tab, text=\"Total Violations Per Zip Code\", variable=graph2, onvalue=1, offvalue=0, background='#ececec')\n",
    "check_zip.grid(row=6,column=0, sticky=W, columnspan=3,  padx=5)\n",
    "\n",
    "check_facility=Checkbutton(graph_tab,text=\"Total Facilities vs. Total Violations\", variable=graph3, onvalue=1, offvalue=0, background='#ececec')\n",
    "check_facility.grid(row=7,column=0, sticky=W, columnspan=3,  padx=5)\n",
    "\n",
    "check_facility=Checkbutton(graph_tab,text=\"Standard Deviation, Range, Totals Comparison\", variable=graph4, onvalue=1, offvalue=0, background='#ececec')\n",
    "check_facility.grid(row=8,column=0, sticky=W, columnspan=3,  padx=5)\n",
    "\n",
    "# Option Buttons \n",
    "\n",
    "# Reset\n",
    "btn_export = ttk.Button(graph_tab, text=\"Export\", command = lambda:export_graphs())\n",
    "btn_export.grid(row=9, column=0, padx=0, sticky=E)\n",
    "\n",
    "\n",
    "# Generate Graph\n",
    "btn_graph = ttk.Button(graph_tab, text=\"Generate Graphs\", command = lambda:generate_graphs())\n",
    "btn_graph.grid(row=9, column=1, pady=20)\n",
    "\n",
    "# Close Button\n",
    "btn_close = ttk.Button(graph_tab, text=\"Close\", command=exit)\n",
    "btn_close.grid(row=9, column=2, sticky=W)\n",
    "\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-seventh",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
