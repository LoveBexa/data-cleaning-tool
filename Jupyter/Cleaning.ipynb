{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skilled-baghdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello welcome to the data cleaning tool. Please upload your files:\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# missing values\n",
    "missing_values = [\"NA\", \"N/A\", \"na\", r\"^\\s*$\", \"\", \" \", \"NaN\"]\n",
    "columns = 'columns'\n",
    "\n",
    "# ----- IMPORT CSV FILES ---- #\n",
    "\n",
    "print(\"Hello welcome to the data cleaning tool. Please upload your files:\")\n",
    "inventory_file = input(\"Please enter the full file location for the inventory file:\")\n",
    "violation_file = input(\"Please enter the full file location for the violation file:\")\n",
    "inspection_file = input(\"Please enter the full file location for the inspection file:\")\n",
    "\n",
    "# /Users/bexa/Documents/Compsci/Advanced Programming/Summative/DataSet1/inventroy.csv\n",
    "# /Users/bexa/Documents/Compsci/Advanced Programming/Summative/DataSet1/violations.csv\n",
    "# /Users/bexa/Documents/Compsci/Advanced Programming/Summative/DataSet1/Inspections.csv\n",
    "\n",
    "inventory = pd.read_csv(inventory_file, keep_default_na=False, na_values=missing_values)\n",
    "violation = pd.read_csv(violation_file, keep_default_na=False, na_values=missing_values)\n",
    "inspection = pd.read_csv(inspection_file, keep_default_na=False, na_values=missing_values)\n",
    "\n",
    "# ---- CLEAN FILE ---- #\n",
    "\n",
    "def clean(df):\n",
    "\n",
    "    # Dropping data with over 50% null to avoid errors \n",
    "    print(\"...10% Dropping empty cells\")\n",
    "    df.dropna(inplace = True) \n",
    "\n",
    "    # Replace NaN, missing values etc with 0\n",
    "    df.fillna(0)\n",
    "    print(\"...20% Neatening missing values\")\n",
    "\n",
    "    print(\"...30% Stripping spaces\")\n",
    "    # Regex finds spaces 2 or more & changes to 1 and strips space before/after \n",
    "    df.columns = [col.strip().replace('  ', ' ') for col in df.columns]\n",
    "\n",
    "    print(\"...40% Converting all to uppercase\")\n",
    "    df.columns = [x.upper() for x in df.columns]\n",
    "    # print(csv_df.columns) to check if it works :)\n",
    "\n",
    "\n",
    "    if \"PE DESCRIPTION\" in df:\n",
    "        print(\"...60% Slicing out & cleaning seating column\")\n",
    "\n",
    "\n",
    "        # Seating numbers only\n",
    "        new_seat_col = df['PE DESCRIPTION'].str.extract('.*\\((.*)\\).*') # print(new_seat_col)\n",
    "\n",
    "        # Remove seating numbers leave behind rest\n",
    "        df['PE DESCRIPTION'] = df['PE DESCRIPTION'].str.replace(r\" \\(.*\\)\",\"\") # print(pe_list)\n",
    "\n",
    "        # New headers\n",
    "        df['SEATING'] = new_seat_col\n",
    "\n",
    "        # Remove Alpha, Commas, Full stop and Spacing\n",
    "\n",
    "        df['SEATING'] = df['SEATING'].str.replace('[a-zA-Z,. ]', '')\n",
    "        # '/^[a-zA-Z0-9,\\.\\s]*$/'\n",
    "        # [a-zA-Z]\n",
    "        \n",
    "    if \"SCORE\" in df:\n",
    "        print(\"...70% Converting to correct data types\")\n",
    "        df[\"SCORE\"] = df[\"SCORE\"].apply(np.int64) \n",
    "\n",
    "    if \"ZIP CODES\" in df:\n",
    "        print(\"...80% Cleaning last bits\")\n",
    "        df[\"ZIP CODES\"] = df[\"ZIP CODES\"].apply(np.int64) \n",
    "        # int_df = df[\"ZIP CODES\"].astype(int)\n",
    "\n",
    "    if \"ACTIVITY DATE\" in df:\n",
    "        print(\"...90% Formatting dates\")\n",
    "        df['ACTIVITY DATE'] =  pd.to_datetime(df['ACTIVITY DATE'], format='%m/%d/%Y')\n",
    "\n",
    "\n",
    "    print(\"...100% Done!\")\n",
    "    \n",
    "    print(df.head(5))\n",
    "\n",
    "    # print(df.head(5))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def second_clean(df):\n",
    "    \n",
    "    print(\"...Implementing a second clean\")\n",
    "\n",
    "    \n",
    "    if \"PROGRAM STATUS\" in df:\n",
    "        print(\"...30% Removing inactive accounts\")\n",
    "        df = df[df['PROGRAM STATUS'] != 'INACTIVE']\n",
    "\n",
    "\n",
    "    if \"ACTIVITY DATE\" in df:\n",
    "        print(\"...60% Formatting dates\")\n",
    "        df['ACTIVITY DATE'] =  pd.to_datetime(df['ACTIVITY DATE'], format='%m/%d/%Y')\n",
    "\n",
    "        # this returns only the year\n",
    "        df['ACTIVITY DATE'] = df['ACTIVITY DATE'].dt.year\n",
    "\n",
    "    if \"SERIAL NUMBER\" and \"FACILITY ID\" in df:\n",
    "        print(\"...90% Drop duplicates\")\n",
    "        df = df.drop_duplicates(subset=['ACTIVITY DATE', 'FACILITY ID', 'SERIAL NUMBER'], keep='last')\n",
    "        \n",
    "    print(\".. 100% Second clean done!\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ---- EXPORT AS JSON ---- #\n",
    "\n",
    "def export_json(file, type):\n",
    "    try:\n",
    "        file_name = input(\"Please enter a file name you'd like to use:\")\n",
    "        new_json_name = file_name + \".json\"\n",
    "        file.to_json(new_json_name, index='true', orient=type) \n",
    "\n",
    "    except NameError:\n",
    "        print(\"You have not loaded or cleaned your files to export yet!\")\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# ---- LETS GO!!! CLEAN DATAFRAMES ----- #\n",
    "\n",
    "\n",
    "df1 = clean(inventory)\n",
    "df2 = clean(violation)\n",
    "df3 = clean(inspection)\n",
    "\n",
    "\n",
    "# ---- HEADER NAMES ----- #\n",
    "\n",
    "# Inventory\n",
    "inventory_headers = [\"FACILITY ID\", \"ZIP CODES\"]\n",
    "# Violation\n",
    "violation_headers = ['SERIAL NUMBER', 'VIOLATION CODE']\n",
    "# Inspection \n",
    "inspection_headers = [\"ACTIVITY DATE\", \"FACILITY ID\", \"SERIAL NUMBER\", \"PROGRAM STATUS\", \"SCORE\", \"SEATING\", \"PE DESCRIPTION\"]\n",
    "\n",
    "\n",
    "# ---- NEW HEADERS ----- #\n",
    "\n",
    "df1_1 = pd.DataFrame(df1, columns=inventory_headers)\n",
    "# print(df1_1.dtypes)\n",
    "\n",
    "\n",
    "df2_1 = pd.DataFrame(df2, columns=violation_headers)\n",
    "# print(df2_1.dtypes)\n",
    "\n",
    "df3_1 = pd.DataFrame(df3, columns=inspection_headers)\n",
    "# print(df3_1.dtypes)\n",
    "\n",
    "# print(df1_1.head(10), df2_1.head(10), df3_1.head(10))\n",
    "\n",
    "\n",
    "# ----MERGE INTO 1 FILE  ----- #\n",
    "\n",
    "# merge. common columns = facility id for ZIP CODES\n",
    "df4_merge = pd.merge(df3_1,df1_1, how='inner', on='FACILITY ID')\n",
    "# merge columns so serial number becomes the violation code \n",
    "df4_merge2 = pd.merge(df4_merge,df2_1, how='inner', on='SERIAL NUMBER')\n",
    "\n",
    "\n",
    "# print(\"SERIAL df4_merge2: \", df4_merge.loc[df4_merge['SERIAL NUMBER'] == 'DA2FXQNN6'])\n",
    "# df4_merge2 = df4_merge2.pop('SERIAL NUMBER')\n",
    "\n",
    "# second clean\n",
    "df4_cleaned = second_clean(df4_merge2)\n",
    "df4_cleaned = df4_cleaned.reset_index(drop=True)\n",
    "\n",
    "print(\"Top 100 of final clean\\n\", df4_cleaned.head(50))\n",
    "\n",
    "# remove duplicates\n",
    "# df4_cleaned = df4_cleaned.drop_duplicates(subset=['FACILITY ID'], keep='last')\n",
    "\n",
    "\n",
    "# ----EXPORT TO JSON  ----- #\n",
    "\n",
    "export_json(df4_cleaned, columns)\n",
    "\n",
    "print(\"Congratulations, your data has been clean and exported into the same folder\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-civilization",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-lancaster",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-niagara",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
